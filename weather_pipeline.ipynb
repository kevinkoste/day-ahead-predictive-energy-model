{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import utility_functions as fn\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads from csv into a new dataframe\n",
    "raw_weather = pd.read_csv('weather_raw2.csv',index_col=1)\n",
    "\n",
    "# reindexes by appropriate datetime\n",
    "raw_weather.index = pd.to_datetime(raw_weather.index,format='%Y-%m-%d %H:00:00 +0000 UTC')\n",
    "raw_weather.index.names = ['']\n",
    "\n",
    "# removes unused columns\n",
    "raw_weather.drop(raw_weather.columns[np.array([0,1,2,3,4,9,10,13,15,16,17,19,20,21,23,24,25,26])],axis=1,inplace=True)\n",
    "\n",
    "# renames columns\n",
    "column_names = ['temp','tmin','tmax','pressure','humidity','wind','rain','snow','clouds']\n",
    "raw_weather.columns = column_names\n",
    "\n",
    "#reorders columns\n",
    "raw_weather = raw_weather[['temp','tmin','tmax','pressure','humidity','wind','clouds','rain','snow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops duplicate rows\n",
    "raw_weather.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY bypass missing 2014-2015 data\n",
    "# weather = raw_weather.truncate('2016-01-01 00:00:00','2019-02-10 00:00:00')\n",
    "\n",
    "weather = raw_weather.copy(deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an 'impute_ok' column; True if time gap is less than 6 hours\n",
    "orig_len = len(weather.index)\n",
    "\n",
    "weather.insert(0,'impute_ok',True)\n",
    "\n",
    "weather['impute_ok'].iloc[1:orig_len]=(weather.index[1:orig_len]-weather.index[0:orig_len-1] <= '06:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexes to add missing rows, for a total length of 53545\n",
    "correct_dt = pd.DatetimeIndex(start='2013-01-01 00:00:00',end='2019-02-10 00:00:00',freq='h')\n",
    "weather = weather.reindex(index=correct_dt)\n",
    "\n",
    "# fills gaps in data with True if less than 6 hours, False if more\n",
    "weather['impute_ok'].fillna(method='bfill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.plot_all(weather,'2013-01-02 00:00:00','2019-02-09 00:00:00')\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error omission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINISH removing outliers, column by column probably\n",
    "\n",
    "# weather['temp'].where(weather < weather.median()+6*weather.std(),inplace=True)\n",
    "# weather['temp'].where(weather > weather.median()-4*weather.std(),inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# assigns NaN precip values to zero, this is an unconfirmed assumption\n",
    "weather['rain'].replace(np.NaN,0,inplace=True)\n",
    "weather['snow'].replace(np.NaN,0,inplace=True)\n",
    "\n",
    "# removes negative clouds measurements\n",
    "weather['clouds'].clip(lower=0,inplace=True)\n",
    "\n",
    "fn.plot_all(weather,'2013-01-02 00:00:00','2019-02-09 00:00:00')\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputes only values that have impute_ok = True\n",
    "# in the future, try linear vs quadratic here\n",
    "# weather.mask(weather['impute_ok']==True, weather.interpolate(method='polynomial', order=7, limit=6), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot over missing chunk to check that the simple impute has yielded expected results\n",
    "fn.plot_feature(weather,'temp','2016-07-15 00:00:00','2016-07-25 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn.gap_check(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputes large segments, ignores period for now\n",
    "# to be replaced by FFT imputation in the future\n",
    "weather = weather.interpolate(method='linear')\n",
    "\n",
    "# removes impute_ok column\n",
    "weather.pop('impute_ok')\n",
    "\n",
    "fn.plot_feature(weather,'temp','2016-07-17 00:00:00','2016-07-23 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function adds columns with data from previous hours associated with the target hour\n",
    "hours_before = np.arange(16,25)\n",
    "weather_with_previous = fn.add_hours_before(weather,hours_before)\n",
    "weather_with_previous.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implements sklearn MinMaxScaler\n",
    "x = weather_with_previous.values\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "scaled = pd.DataFrame(x_scaled)\n",
    "scaled.columns = weather_with_previous.columns\n",
    "scaled.index = weather_with_previous.index\n",
    "\n",
    "scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled.to_csv('weather_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unused code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # returns index labels where nan values appear for a certain column\n",
    "# nan_index = weather['temp'].index[weather['temp'].apply(np.isnan)]\n",
    "# nan_index\n",
    "\n",
    "# correct and complete datetime index for the date range considered\n",
    "# dt = pd.DatetimeIndex(start='2013-01-01 00:00:00',end='2019-02-10 00:00:00',freq='h')\n",
    "\n",
    "# # renames (here, makes lowercase) column labels using a simple loop\n",
    "# df.columns = [x.lower() for x in df.columns]\n",
    "\n",
    "# # implements sklearn scaler\n",
    "# from sklearn import preprocessing\n",
    "# x = df.values #returns a numpy array\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = scaler.fit_transform(x)\n",
    "# df = pandas.DataFrame(x_scaled)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
